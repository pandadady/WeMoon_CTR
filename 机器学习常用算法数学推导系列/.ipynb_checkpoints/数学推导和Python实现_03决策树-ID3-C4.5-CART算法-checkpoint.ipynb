{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID3,C4.5和CART算法python实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信息增益"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树中的ID3和c4.5算法是基于香农信息论。\n",
    "香农熵：给定可能性分布P和实例S， 那么信息熵可以如下计算：  \n",
    "$Entropie(P) =-\\sum_{i=1}^{n}p_i * log(p_i)$\n",
    "\n",
    "信息增益G(P, T): 决策树通过对不同特征进行切分判断来进行分类。那怎么判断什么哪个特征比较合适。可以用信息增益来测量所有样本特征的混合程度，选择比较混乱的特征(熵比较大), 经过叫少的判断即可区分。计算公式如下：  \n",
    "$Gain(p, T)  = Entropie(P) - \\sum_{i=1}^{n}(p_i * Entropie(p_i))$  \n",
    "pi表示T特征中发生的可能性。\n",
    "\n",
    "下面通过一个例子来进行简单计算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>humility</th>\n",
       "      <th>outlook</th>\n",
       "      <th>play</th>\n",
       "      <th>temp</th>\n",
       "      <th>windy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>high</td>\n",
       "      <td>sunny</td>\n",
       "      <td>no</td>\n",
       "      <td>hot</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>high</td>\n",
       "      <td>sunny</td>\n",
       "      <td>no</td>\n",
       "      <td>hot</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>high</td>\n",
       "      <td>overcast</td>\n",
       "      <td>yes</td>\n",
       "      <td>hot</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>high</td>\n",
       "      <td>rainy</td>\n",
       "      <td>yes</td>\n",
       "      <td>mild</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>normal</td>\n",
       "      <td>rainy</td>\n",
       "      <td>yes</td>\n",
       "      <td>cool</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>normal</td>\n",
       "      <td>rainy</td>\n",
       "      <td>no</td>\n",
       "      <td>cool</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>normal</td>\n",
       "      <td>overcast</td>\n",
       "      <td>yes</td>\n",
       "      <td>cool</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>high</td>\n",
       "      <td>sunny</td>\n",
       "      <td>no</td>\n",
       "      <td>mild</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>normal</td>\n",
       "      <td>sunny</td>\n",
       "      <td>yes</td>\n",
       "      <td>cool</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>normal</td>\n",
       "      <td>rainy</td>\n",
       "      <td>yes</td>\n",
       "      <td>mild</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>normal</td>\n",
       "      <td>sunny</td>\n",
       "      <td>yes</td>\n",
       "      <td>mild</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>high</td>\n",
       "      <td>overcast</td>\n",
       "      <td>yes</td>\n",
       "      <td>mild</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>normal</td>\n",
       "      <td>overcast</td>\n",
       "      <td>yes</td>\n",
       "      <td>hot</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>high</td>\n",
       "      <td>rainy</td>\n",
       "      <td>no</td>\n",
       "      <td>mild</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   humility   outlook play  temp  windy\n",
       "0      high     sunny   no   hot  False\n",
       "1      high     sunny   no   hot   True\n",
       "2      high  overcast  yes   hot  False\n",
       "3      high     rainy  yes  mild  False\n",
       "4    normal     rainy  yes  cool  False\n",
       "5    normal     rainy   no  cool   True\n",
       "6    normal  overcast  yes  cool   True\n",
       "7      high     sunny   no  mild  False\n",
       "8    normal     sunny  yes  cool  False\n",
       "9    normal     rainy  yes  mild  False\n",
       "10   normal     sunny  yes  mild   True\n",
       "11     high  overcast  yes  mild   True\n",
       "12   normal  overcast  yes   hot  False\n",
       "13     high     rainy   no  mild   True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log\n",
    "\n",
    "#加载数据\n",
    "df = pd.read_csv('./example_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义简单的熵计算函数：\n",
    "def entropy(label_set):\n",
    "    return -np.sum(label_set * np.log2(label_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9402859586706311"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 全集S的熵：\n",
    "entropy_s = entropy([9/14, 5/14]) # 两个类别\n",
    "entropy_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlook   play\n",
      "overcast  yes     4\n",
      "rainy     no      2\n",
      "          yes     3\n",
      "sunny     no      3\n",
      "          yes     2\n",
      "dtype: int64\n",
      "------------------------------\n",
      "temp  play\n",
      "cool  no      1\n",
      "      yes     3\n",
      "hot   no      2\n",
      "      yes     2\n",
      "mild  no      2\n",
      "      yes     4\n",
      "dtype: int64\n",
      "------------------------------\n",
      "humility  play\n",
      "high      no      4\n",
      "          yes     3\n",
      "normal    no      1\n",
      "          yes     6\n",
      "dtype: int64\n",
      "------------------------------\n",
      "windy  play\n",
      "False  no      2\n",
      "       yes     6\n",
      "True   no      3\n",
      "       yes     3\n",
      "dtype: int64\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for col in ['outlook', 'temp', 'humility', 'windy']:\n",
    "    print(df.groupby([col, 'play']).size())\n",
    "    print('-' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 其中每个类别对应的play情况如上， 因此信息增益如下计算：\n",
    "gain_s_outlook = entropy_s - 4/14 * entropy([1]) - 5/14*entropy([2/5, 3/5]) - 5/14*entropy([3/5, 2/5])\n",
    "# 同样方法可以计算出另外两个特征的信息增益\n",
    "gain_s_temperature = entropy_s - 4/14*entropy([1/4, 3/4]) - 4/14 * entropy([2/4, 2/4]) - 6/14*entropy([2/6, 4/6])\n",
    "gain_s_humidity = entropy_s - 7/14 * entropy([4/7, 3/7]) - 7/14 * entropy([1/7, 6/7])\n",
    "gain_s_wind = entropy_s - 5/14*entropy([3/5, 2/5]) - 9/14 * entropy([2/9, 7/9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24674981977443933,\n",
       " 0.15183550136234164,\n",
       " 0.10224356360985076,\n",
       " 0.02922256565895487)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4个特征的信息增益计算完毕，选组最大的特征作为根节点进行切分\n",
    "gain_s_outlook, gain_s_humidity, gain_s_wind, gain_s_temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择outlook作为根节点切分之后，分为3个分支。其中overcast分支不用再进行判断。其余两个分支按照同样方法进行切分，直到不可再分。\n",
    "这就是ID3算法的计算过程。\n",
    "缺点：如上计算，假设outlook中共计有14个类别， 其信息增益当然最大， 应该选择作为根节点切分，但此时并不一定是最好的切分特征，因为不具有泛化能力。此时选择信息增益比来进行改进。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信息增益比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以使用如下公式计算：  \n",
    "先计算splitinfo：  \n",
    "$splitinfo(p, T) = -\\sum_{j=1}^{n}(\\frac{|p_j|}{p}) * log2(\\frac{|p_j|}{p})$ \n",
    "\n",
    "再计算gainratio：  \n",
    "$gainratio(p, T) = \\frac{Gain(P, T)}{splitinfo(p, T)}$  \n",
    "\n",
    "上面的过程已经计算除了分子，下面主要是分母的计算，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitinfo_s_outlook = entropy([5/14, 5/14, 4/14])\n",
    "splitinfo_s_temperature = entropy([4/14, 4/ 14, 6/14])\n",
    "splitinfo_s_humidity = entropy([7/14, 7/14])\n",
    "splitinfo_s_wind = entropy([5/14, 9/14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5774062828523454\n",
      "1.5566567074628228\n",
      "1.0\n",
      "0.9402859586706311\n"
     ]
    }
   ],
   "source": [
    "print(splitinfo_s_outlook)\n",
    "print(splitinfo_s_temperature)\n",
    "print(splitinfo_s_humidity)\n",
    "print(splitinfo_s_wind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15642756242117528\n",
      "0.018772646222418813\n",
      "0.15183550136234164\n",
      "0.1087366695918781\n"
     ]
    }
   ],
   "source": [
    "print(gain_s_outlook / splitinfo_s_outlook)\n",
    "print(gain_s_temperature / splitinfo_s_temperature)\n",
    "print(gain_s_humidity / splitinfo_s_humidity)\n",
    "print(gain_s_wind / splitinfo_s_wind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择信息增益比高的特征进行类别切分，其后过程和ID3算法类似。\n",
    "经过以上计算，上述两种决策树还有已下特点：\n",
    "1. 缺失值的处理\n",
    "如果某些特征有少量缺失值，决策树通过计算信息增益比，比如上述outlook特征中某个值缺失，但计算的结果相差不大， 因此可以处理少量缺失值的数据。\n",
    "2. 连续行特征\n",
    "与ID3只能处理类别数据不同，C4.5还可以处理连续数据。方法是去连续数据中间的值，将该特征分为两类，进而计算信息增益比，也是选则最大值进行切分。\n",
    "3. 剪枝\n",
    "根据训练集生成决策树，通常会对数据过拟合，并且对一些噪声值比较敏感。为了提高正确率， 需要对树进行剪枝。剪枝是一种通过删除树中提供很少分类实例的部分来减少决策树的大小的一种方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基尼指数（Gini index）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以使用如下公式计算：  \n",
    "先计算splitinfo：\n",
    "\n",
    "$Gini(D) = \\sum_{k=1}^{K}{p_k}({1-p_k})=1-\\sum_{k=1}^{K}{p_k^2}$ \n",
    "\n",
    "再计算gainratio：  \n",
    "$Gini(D|A) = \\sum_{k=1}^{K}\\frac{|D_k|}{|D|}{Gain(D_k)}$  \n",
    "\n",
    "上面的过程已经计算除了分子，下面主要是分母的计算，如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输入数值型参数\n",
    "#定义Gini基尼指数函数\n",
    "def gini(nums):\n",
    "#     return 1 - np.sum(np.power(nums, 2))\n",
    "    gini = np.sum([p*(1-p) for p in nums]) \n",
    "    return gini "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以看到不同的特征分为两类， 计算基尼系数，选择较小的值进行切分:\n",
    "gini_s_outlook = gini([5/14, 4/14,5/14])\n",
    "gini_s_temperature = gini([4/14, 4/14, 6/14])\n",
    "gini_s_humidity = gini([7/14, 7/14])\n",
    "gini_s_wind = gini([8/14, 6/14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6632653061224489, 0.5, 0.4897959183673469, 0.6530612244897959)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_s_outlook, gini_s_humidity, gini_s_wind, gini_s_temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "因此选择最小的特征wind，构建利用上述分为两部分分别计算gini系数，从而确定分类类别，构建二叉树进行决策。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
